"""
A module for post-processing of reconstructed images generated by ORGANIC.
"""

from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from astropy.io import fits
import sys
import matplotlib.pyplot as plt
import numpy as np
import scipy as sc
import os
import copy

import organic.auxiliary.ReadOIFITS as oi
from organic.organic import Data


# class to represent a cube of images output by ORGANIC
class Cube:
    """
    A class to represent a cube of images output by ORGANIC.

    Parameters
    ----------
    dir : str
        Directory containing the cube file.
    file : str, optional
        Cube file name (default is "cube.fits").
    npca : int, optional
        Number of PCA components (default is 3).
    nkmeans : int, optional
        Number of K-means clusters (default is 3).
    nbest : int, optional
        Number of best images to single out (default is 6).
    show_plots : bool, optional
        Whether to show plots (default is True).

    Attributes
    ----------
    dir : str
        Directory containing the cube file.
    file : str
        Cube file name.
    nkmeans : int
        Number of K-means clusters.
    npca : int
        Number of PCA components.
    nbest : int
        Number of best images to single out.
    show_plots : bool
        Whether to show plots.
    cube : ndarray
        Cube of images.
    hdr : Header
        FITS header.
    ps : float
        Pixel scale.
    n : int
        Number of pixels.
    x2, y2 : float
        Position of the secondary.
    fs, f2 : float
        Flux ratios.
    ud : float
        Uniform diameter of the primary.
    denv, dsec : float
        Spectral indices.
    mu : float
        Regularization term weight.
    fdata, ftot, frgl : ndarray
        Metrics data.
    pca : ndarray
        PCA-projected images.
    kmeans : ndarray
        K-means cluster labels.
    centers : ndarray
        K-means cluster centers.
    bestimages : ndarray
        Best images.
    bestmetrics : ndarray
        Metrics of the best images.
    kmeanfdata, keamnfrgl, kmeanftot : list
        Median loss terms per cluster group.
    medians, stds : list
        Median and standard deviation images per cluster group.
    counts : list
        Number of images in each cluster group.
    groups : list
        Cube of images per cluster group.
    d : float
        Distance spanned by image on each side of axes.
    x, y, r, angle : ndarray
        Coordinates and angles.
    radii : ndarray
        Radii for radial profiles.
    profile, noises, rms : ndarray
        Radial profile data.
    """

    # initialization function, notes it does a bunch of calculations as well
    # note the number of PCA components and Kmeans cluster groups to divide the data into
    def __init__(self, dir, file="cube.fits", npca=3, nkmeans=3, nbest=6, show_plots=True):
        self.dir = dir  # directory in which to find cube
        self.file = file  # filename of cube file
        self.nkmeans = nkmeans  # number of K means groups to subdivide output into
        self.npca = npca  # number of PCA components to use
        self.nbest = nbest  # number of best images to single out
        self.show_plots = show_plots  # whether or not to show plots
        self.read()  # read in the Cube.fits file output by organic
        self.do_pca()  # perform PCA analysis
        self.do_kmeans()  # do K means clustering
        self.plot_kmeans()  # plot the results of the K means clustering, including in PCA space and loss terms
        self.plot_median_images()  # plot all the median images of the groups
        # NOTE: getting and plotting the best images requires a separate call to the give_best() method

    # function to read in an ORGANIC cube of output images, also sets up the coordinates
    def read(self):
        """
        Reads the cube file and sets up coordinates.
        """
        path = os.path.join(self.dir, self.file)
        hdul = fits.open(path)
        cube = hdul[0].data  # retrieve the images data from the Primary extension
        self.hdr = hdul[0].header  # retrieve the header from the primary extension
        self.ps = hdul[0].header["CDELT2"]  # retrieve the size of the pixelscale from the header
        self.n = hdul[0].header["NAXIS2"]  # retrieve the amount of pixels from the header

        self.x2 = hdul[0].header["SDEX2"]  # position of the secondary
        self.y2 = hdul[0].header["SDEY2"]
        self.fs = hdul[0].header["SFLU1"]  # flux ratio of the primary star
        self.f2 = hdul[0].header["SFLU2"]  # flux ratio of the secondary
        self.ud = hdul[0].header["SUD1"]  # uniform diameter of the primary
        self.denv = hdul[0].header["SIND0"]  # spectral index of the environment
        self.dsec = hdul[0].header["SIND2"]  # spectral index of the secondary
        self.cube = cube  # cube of images

        # Read in the metrics columns associated to each image.
        self.mu = hdul[0].header["MU"]  # set regularization term weight
        metrics = hdul[1].data
        self.fdata = metrics["fdata"]
        self.ftot = metrics["ftot"]
        self.frgl = metrics["frgl"]

        # call function to set up coordinates
        self.set_coord()

    # function to perfrom the PCA decomposition
    def do_pca(self):
        """
        Performs PCA decomposition on the cube of images.
        """
        cube = copy.deepcopy(self.cube)  # do a deepcopy here because reshape does not guarantee making a copy
        shape = cube.shape
        cube = np.reshape(cube, (shape[0], shape[1] * shape[2]))
        pca = PCA(n_components=self.npca, random_state=128)  # create a PCA object
        pca = pca.fit(cube)  # fit to cube of images to define the PCA transform
        print(f"Explained variance ratio over principal components: {pca.explained_variance_ratio_}")
        print(f"Total explained variance ratio over chosen #components: {sum(pca.explained_variance_ratio_)}")
        cube_pca = pca.transform(cube)  # actually apply it to get dimensionality reduction
        self.pca = cube_pca  # add the pca-projected images to the object properties

    # perform Kmeans clustering on the PCA
    def do_kmeans(self):
        """
        Performs K-means clustering on the PCA-projected images.
        """
        pca = self.pca
        kmeans = KMeans(n_clusters=self.nkmeans, n_init=500, random_state=128)  # initialize clustering in PCA space
        clusters = kmeans.fit_predict(pca)  # return cluster labels in PCA space
        centers = kmeans.cluster_centers_  # retrieve the centres of the kmeans clusters in PCA space
        self.kmeans = clusters  # assign to appropriate object attributes
        self.centers = centers
        self.set_kmeans_metrics()  # add the kmeans metrics to the instance attributes

    # function to single out the n best images in the cube, store them in the appropriate properties, plot them
    # and write them to a file
    def give_best(self):
        """
        Singles out the best images and plots them.
        """
        fdata = self.fdata
        ftot = self.ftot
        frgl = self.frgl
        cube = self.cube
        nbest = self.nbest  # number of best images to single out of the cube

        idx = ftot.argsort()  # get indices which would sort the ftot loss array

        zebest, zemetrics = [], []  # arrays to store in the best
        for i in np.arange(nbest):
            idx_nbest = np.where(idx == i)[0]  # index for the nth best image
            zebest.extend(cube[idx_nbest, :, :])  # get nth best image
            zemetrics.append(np.array([ftot[idx_nbest][0], fdata[idx_nbest][0], frgl[idx_nbest][0]]))  # get its metrics

        self.bestimages = np.array(zebest)  # store best images and metrics in the appropriate attributes
        self.bestmetrics = np.array(zemetrics)

        self.plot_best()  # plot the n best images
        self.write_best()  # write them to a fits file

    # function to write the best images to separate fits files
    def write_best(self):
        """
        Writes the best images to separate FITS files.
        """
        best = self.bestimages  # get best image
        metrics = self.bestmetrics  # get their metrics
        ftot, fdata, frgl = metrics[:, 0], metrics[:, 1], metrics[:, 2]  # get lists of the metrics terms
        nbest = self.nbest
        for i in np.arange(self.nbest):
            hdr = self.hdr  # take the header from the primary cube header
            hdr["NBEST"] = i + 1
            hdr["CDELT1"] = hdr["CDELT1"]
            hdr["FTOT"] = ftot[i]
            hdr["FDATA"] = fdata[i]
            hdr["FRGL"] = frgl[i]
            img = best[i, :, :]
            hdu = fits.PrimaryHDU(img, header=hdr)
            hdul = fits.HDUList([hdu])
            hdul.writeto(os.path.join(self.dir, f"best_image{i + 1}.fits"), overwrite=True)

    # function to plot the n best images
    def plot_best(self):
        """
        Plots the best images.
        """
        best = self.bestimages
        metrics = self.bestmetrics
        ftot, fdata, frgl = metrics[:, 0], metrics[:, 1], metrics[:, 2]
        nbest = self.nbest
        ncols = int(np.sqrt(nbest))
        nrows = int(np.sqrt(nbest))
        if nrows * ncols != nbest:
            ncols += 1
        indices = np.indices((nrows, ncols))  # get row and column indices matrices
        indrow = indices[0].ravel()  # ravel these into 1d arrays
        indcols = indices[1].ravel()
        fig, axs = plt.subplots(ncols=ncols, nrows=nrows, sharey=True, sharex=True)
        d = self.d  # distance spanned by image on each side of axes
        for i in np.arange(nbest):
            ax = axs[indrow[i], indcols[i]]
            image = np.array(best[i, ::-1, :])  # NOTE: fukin flip the image again due to numpy vs FITS convention

            # NOTE: have to correct sky coordinates for half-pixel offset to the top-left
            # of the phase center (x,y) = (0,0) relative to the geometric center of the
            # image. The FOV is not symmetric around the (x,y) = (0,0) position, instead
            # being half a pixel larger towards the bottom and towards the right for
            # even images.
            ax.imshow(
                image, extent=(d - self.ps / 2, -d - self.ps / 2, -d - self.ps / 2, d - self.ps / 2), cmap="inferno"
            )
            ax.set_xlim(d - self.ps / 2, -d - self.ps / 2)
            ax.text(0.8 * d, 0.8 * d, f"chi2={fdata[i]:2.2f}", color="white", size=9)
            ax.set_title(f"Best model {i + 1}")
            if indcols[i] == 0:
                ax.set_xlabel(r"$\Delta \alpha$ (mas)")
            if indrow[i] == indrow[-1]:
                ax.set_ylabel(r"$\Delta \delta$ (mas)")
        plt.tight_layout()
        plt.savefig(os.path.join(self.dir, f"best_{nbest}_images.png"), dpi=250)
        if self.show_plots:
            plt.show()

    # function to add the kmeans metrics to the attributes of the class; currently not really used anywhere
    def set_kmeans_metrics(self):
        """
        Adds the K-means metrics to the attributes.
        """
        clusters = self.kmeans
        nk = self.nkmeans
        fdata = self.fdata
        frgl = self.frgl
        ftot = self.ftot

        fdatacluster, frglcluster, ftotcluster = [], [], []  # lists to contain median loss terms over the clusters
        # iterate over cluster labels
        for i in np.arange(nk):
            fdatak = fdata[clusters == i]  # retrieve fdata at all positions where the cluster label = the relevant one
            frglk = frgl[clusters == i]  # same for regularization
            ftotk = ftot[clusters == i]
            fdatacluster.append(np.median(fdatak))
            frglcluster.append(np.median(frglk))
            ftotcluster.append(np.median(ftotk))
        self.kmeanfdata = fdatacluster  # add median loss terms per cluster group to appropriate properties
        self.keamnfrgl = frglcluster
        self.kmeanftot = ftotcluster

    # function to plot the clustering results
    def plot_kmeans(self):
        """
        Plots the clustering results.
        """
        fig, ax = plt.subplots()
        # scatter PCA projection weights, coloured by the associated cluster
        plt.scatter(self.pca[:, 0], self.pca[:, 1], c=self.kmeans)
        centroids = self.centers
        # label the clusters with a text label
        for centre, k in zip(centroids, np.arange(self.nkmeans)):
            plt.text(centre[0], centre[1], s=f"{k}", size="large", backgroundcolor="lightgray", alpha=0.6)
        plt.ylabel("Principal component 2")
        plt.xlabel("Principal component 1")
        plt.tight_layout()
        plt.savefig(os.path.join(self.dir, "pca_sets.png"), dpi=250)
        if self.show_plots:
            plt.show()

        # actually scatterplot the loss terms
        fig, ax = plt.subplots()
        plt.scatter(self.fdata, self.frgl, c=self.kmeans)
        for fd, fr, k in zip(self.kmeanfdata, self.keamnfrgl, np.arange(self.nkmeans)):
            plt.text(
                fd, fr, s=f"{k}", size="large", backgroundcolor="lightgray", alpha=0.6
            )  # plot text label at mean loss positions
        plt.ylabel("frgl")
        plt.xlabel("fdata")
        plt.tight_layout()
        plt.savefig(os.path.join(self.dir, "pca_metrics.png"), dpi=250)
        if self.show_plots:
            plt.show()

    # TODO: this one seems outdated, don't think it's used a lot
    def plot_pca(self):
        """
        Plots the PCA results.
        """
        fig, ax = plt.subplots()
        plt.scatter(self.pca[:, 0], self.pca[:, 1])
        if self.show_plots:
            plt.show()

    # function to group images properly per kmeans cluster and add corresponding instance attributes
    def group_images(self):
        """
        Groups images per K-means cluster.
        """
        idx = list(self.kmeans)  # get cluster indices for images in cube
        cube = self.cube
        medians, stds = [], []
        counts, groups = [], []
        for k in np.arange(self.nkmeans):
            counts.append(idx.count(k))
            cub = []
            for image, i in zip(cube, idx):
                if i == k:
                    cub.append(image)
            cub = np.array(cub)
            groups.append(cub)
            median_img = np.median(cub, axis=0)
            median_img /= np.sum(median_img)
            medians.append(median_img)
            stds.append(np.std(cub, axis=0))
        self.medians = medians  # median images per cluster group
        self.stds = stds  # standard deviation image per cluster group
        self.counts = counts  # amount of images in each group
        self.groups = groups  # a cube of images per cluster group

    # function to plot the median images per clustering group
    def plot_median_images(self):
        """
        Plots the median images per clustering group.
        """
        self.group_images()
        images = np.array(self.medians)
        fig, axs = plt.subplots(ncols=self.nkmeans, sharey=True)
        d = self.d
        for ax, i in zip(axs, np.arange(self.nkmeans)):
            ax.imshow(
                images[i, ::-1, :],
                extent=(d - self.ps / 2, -d - self.ps / 2, -d - self.ps / 2, d - self.ps / 2),
                cmap="inferno",
            )
            ax.set_xlim(d - self.ps / 2, -d - self.ps / 2)
            ax.set_title(f"{i}: {self.counts[i]} images")
            ax.set_xlabel(r"$\Delta \alpha$ (mas)")
            ax.set_ylabel(r"$\Delta \delta$ (mas)")
        plt.tight_layout()
        plt.savefig(os.path.join(self.dir, "median_image_across_sets.png"), dpi=250)
        if self.show_plots:
            plt.show()

    # function to write median images per kmeans cluster to fits files
    def write_median_images(self, add_stars=False):
        """
        Writes median images per K-means cluster to FITS files.

        Parameters
        ----------
        add_stars : bool, optional
            Whether to add stars to the images (default is False).
        """
        if add_stars:
            self.add_stars()
        images = np.array(self.medians)
        for i in np.arange(len(self.counts)):
            hdr = self.hdr  # primary cube.fits header
            hdr["SETCLUST"] = i  # which kmeans set the image belongs to
            hdr["CDELT1"] = hdr["CDELT1"]  # NOTE: what does this even do?
            img = images[i, :, :]
            hdu = fits.PrimaryHDU(img, header=hdr)
            hdul = fits.HDUList([hdu])
            hdul.writeto(os.path.join(self.dir, f"median_image_cluster_set{i}.fits"), overwrite=True)

    # static method to add a Gaussian to a random image
    # NOTE: currently not really used in a meaningful sense
    @staticmethod
    def add_gaussian(image, x, y, f):
        """
        Adds a Gaussian to an image.

        Parameters
        ----------
        image : ndarray
            The image to which the Gaussian will be added.
        x, y : float
            Coordinates of the Gaussian center.
        f : float
            Flux of the Gaussian.

        Returns
        -------
        ndarray
            The image with the added Gaussian.
        """
        nx, ny = image.shape
        xg = np.linspace(-nx / 2.0 - x, nx / 2.0 - x, nx)
        yg = np.linspace(-ny / 2.0 - y, ny / 2.0 - y, ny)
        xg2, yg2 = np.meshgrid(xg, yg)
        R = np.sqrt(xg2**2 + yg2**2)
        c = 0.2
        Gauss = np.exp(-((R) ** 2) / (2 * c**2))
        # fig, ax = plt.subplots()
        # plt.imshow(Gauss)
        # plt.scatter(nx/2.,nx/2.)
        # plt.show()
        #

        Gauss /= np.sum(Gauss)
        image += f * Gauss
        if np.sum(image) != 0:
            image /= np.sum(image)
        return image

    # function to add the stars in the form of Gaussians
    # NOTE: kinda stupid to add these as gaussians in hindsight, not currently used in any meaningful sense
    def add_stars(self):
        """
        Adds stars in the form of Gaussians to the median images.
        """
        images = np.array(self.medians)
        xb = self.x2
        yb = self.y2
        fs = self.fs / 100
        fb = self.f2 / 100
        newimages = []
        for i in np.arange(len(self.counts)):
            img = images[i, :, :]
            img /= np.sum(img)
            Gs = self.add_gaussian(np.zeros_like(img), 0.0, 0.0, fs)
            xbp = xb / self.ps
            ybp = yb / self.ps
            Gb = self.add_gaussian(np.zeros_like(img), xbp, ybp, fb)

            final = (1 - fs - fb) * img + fs * Gs + fb * Gb
            newimages.append(final)
        self.medians = newimages

    # function to get the chi2 calculated
    # NOTE: currently not used anywhere
    def get_chi2(self, dir, file):
        """
        Calculates the chi-squared value.

        Parameters
        ----------
        dir : str
            Directory containing the data file.
        file : str
            Data file name.
        """
        data = Data(dir, file)
        V2, V2e, CP, CPe, waveV2, waveCP, u, u1, u2, u3, v, v1, v2, v3 = data.get_data()
        self.data = data

        # setting the ft coordinates
        ftps = 1000 * 3600 * 180 / np.pi / self.d
        ftd = 1000 * 3600 * 180 / np.pi / self.ps
        ftx0 = np.linspace(-ftd, ftd, self.n)  # - +
        fty0 = np.linspace(-ftd, ftd, self.n)  # - +
        ftx, fty = np.meshgrid(ftx0, fty0)
        self.wave0 = 2.2e-6

        imgs = np.array(self.medians)
        for i in np.arange(self.nkmeans):
            image = imgs[i, :, :]
            image /= np.sum(image)
            ftimg = np.fft.ifftshift(image, axes=(0, 1))
            ftimg = np.fft.fft2(ftimg)
            ftimg = np.fft.fftshift(ftimg, axes=(0, 1))

            # fig, ax = plt.subplots()
            # plt.imshow(np.abs(ftimg), extent=( -ftd, ftd, -ftd, ftd) )
            # plt.scatter(u, v, marker='+')
            # plt.scatter(-u, -v, marker='+')
            # plt.show()
            #

            FourierRe = sc.interpolate.interp2d(ftx0, fty0, ftimg.real, bounds_error=True, kind="cubic")
            FourierIm = sc.interpolate.interp2d(ftx0, fty0, ftimg.imag, bounds_error=True, kind="cubic")

            # FourierRe = sc.interpolate.RectBivariateSpline(ftx0, fty0, ftimg.real)
            # FourierRe = sc.interpolate.RectBivariateSpline(ftx0, fty0, ftimg.real)

            # fig,ax = plt.subplots()
            # plt.imshow(np.abs(ftimg))
            # plt.show()
            #
            #            print( f'u shape is {u.shape} and v shape is {v.shape}' )
            Vis, Phi = self.give_vis(u, v, waveV2, FourierRe, FourierIm)

            chi2v2 = ((np.power(Vis, 2) - V2) / V2e) ** 2
            print(f"len V2: {len(V2)}")
            chi2v2 = np.sum(chi2v2) / len(V2)

            # fig, ax = plt.subplots()
            # plt.scatter(np.sqrt(u**2, v**2), np.power(Vis,2) )
            # plt.scatter(np.sqrt(u**2, v**2), V2)
            # plt.show()
            #

    # Function to calculate the visibility
    # NOTE: currently not used in a meaningfull way
    def give_vis(self, u, v, wave, FTre, FTim):
        """
        Calculates the visibility.

        Parameters
        ----------
        u, v : ndarray
            U and V coordinates.
        wave : ndarray
            Wavelengths.
        FTre, FTim : callable
            Real and imaginary parts of the Fourier transform.

        Returns
        -------
        tuple
            Absolute value and phase of the visibility.
        """
        # interpolate in the Fourier plane
        # Vimg = FTre(u, v) + 1j*FTim(u, v)
        # Vimg = [ FTre(ui, vi) + 1j*FTim(ui, vi) for ui, vi in zip(u, v)]
        Vimg = np.zeros_like(u).astype(complex)
        for i, (ui, vi) in enumerate(zip(u, v)):
            Vimg[i] = FTre(ui, vi) + 1j * FTim(ui, vi)
        # Vimg = np.array(Vimg)

        # add sparco on top
        f1 = self.fs / 100 * np.power(wave / self.wave0, -4)
        f2 = self.f2 / 100 * np.power(wave / self.wave0, self.dsec)
        fimg = (1 - self.fs / 100 - self.f2 / 100) * np.power(wave / self.wave0, self.denv)

        V1 = 0j + 2 * sc.special.jv(1, np.pi * self.ud / 1000 / 3600 / 180 * np.pi * np.sqrt(u**2, v**2)) / (
            np.pi * self.ud / 1000 / 3600 / 180 * np.pi * np.sqrt(u**2, v**2)
        )

        alpha = self.x2 / 1000 / 3600 * np.pi / 180
        delta = self.y2 / 1000 / 3600 * np.pi / 180
        V2 = np.exp(-2 * np.pi * 1j * (u * alpha + v * delta))

        # Vtot = np.divide(np.multiply(fimg , Vimg) + np.multiply(f1, V1) + np.multiply(f2, V2 ), fimg + f1 + f2)

        Vtot = (fimg * Vimg + f1 * V1 + f2 * V2) / (fimg + f1 + f2)

        #        print(Vtot.shape)

        return np.abs(Vtot), np.arctan2(Vtot.imag, Vtot.real)

    # NOTE: not used anywhere at the moment
    def plot_set(self, set):
        """
        Plots a set of images.

        Parameters
        ----------
        set : int
            Index of the set to plot.
        """
        images = self.groups[set]
        number = self.counts[set]

        fig, axs = plt.subplots(ncols=5, nrows=3)
        i = -1
        for axy in axs:
            for ax in axy:
                i += 1
                if i < number - 1:
                    ax.imshow(images[i, ::-1, :], cmap="inferno")
        plt.tight_layout()
        if self.show_plots:
            plt.show()

    # function to add image pixel coordinates and values to the Cube object
    def set_coord(self):
        """
        Sets up image pixel coordinates and values.
        """
        n = self.n
        xr = np.arange(n) + 1
        x = -(xr - self.n / 2) * self.ps
        y = -(xr - self.n / 2) * self.ps
        d = n * self.ps / 2.0  # distance spanned along each side
        x = np.linspace(d - self.ps / 2, -(d - self.ps / 2), n)
        y = np.linspace(-(d - self.ps / 2), d - self.ps / 2, n)  # this is wrong btw
        x2, y2 = np.meshgrid(x, y)  # make a meshgrid
        r = np.sqrt(x2**2 + y2**2)  # radial coordinate
        angle = np.arctan2(y2, x2)  # position angle

        self.d = d  # distance spanned along each side of the axis by the image
        self.x = x2  # x positions in meshgrid style array
        self.y = -y2  # y positions in meshgrid style array
        self.r = r  # radial coordinates in meshgrid style array
        self.angle = angle  # position angles of the points in meshgrid style array

    # function to compute and plot radial profiles of the intensity
    def get_radial_profiles(self, R=20, set=-1):
        """
        Computes and plots radial profiles of the intensity.

        Parameters
        ----------
        R : int, optional
            Number of radial bins (default is 20).
        set : int, optional
            Index of the set to use (default is -1, which uses the entire cube).
        """
        if set == -1:
            cube = self.cube
            image = np.median(cube, axis=0)
            image /= np.sum(image)
            std = np.std(cube, axis=0)
        else:
            cube = self.groups[set]  # cube for specific clustering group
            image = np.median(cube, axis=0)
            image /= np.sum(image)
            std = np.std(cube, axis=0)

        self.compute_radial_profile(R, image, std)
        self.plot_radial_profile()

    def compute_radial_profile(self, R, image, noise):
        """
        Computes the radial profile.

        Parameters
        ----------
        R : int
            Number of radial bins.
        image : ndarray
            Image data.
        noise : ndarray
            Noise data.
        """
        # noise /= np.max(image)
        # image /= np.max(image)
        dr = (self.d - self.ps) / R
        radii_m = np.linspace(self.ps, self.d - dr, R)
        radii_p = np.linspace(self.ps + dr, self.d, R)
        self.radii = (radii_m + radii_p) / 2.0
        profile, noises, rms = [], [], []
        for rad_m, rad_p in zip(radii_m, radii_p):
            mask = (self.r >= rad_m) * (self.r < rad_p)
            reduced_image = image[mask != 0]
            reduced_noise = noise[mask != 0]
            fluxi = np.average(reduced_image)
            noisei = np.average(reduced_noise)
            rmsi = np.std(reduced_image)  # /len(reduced_image)
            profile.append(fluxi)
            noises.append(noisei)
            rms.append(rmsi)

        self.profile = np.array(profile)
        self.noises = np.array(noises)
        self.rms = np.array(rms)

    def plot_radial_profile(self):
        """
        Plots the radial profile.
        """
        fig, ax = plt.subplots()
        ax.plot(self.radii, self.profile, label="profile", color="black")
        ax.plot(self.radii, self.noises, label="noise", color="blue")
        ax.plot(self.radii, self.rms, label="azim. std.", color="red")
        plt.yscale("log")
        plt.legend()
        if self.show_plots:
            plt.show()

        fig, ax = plt.subplots()
        ax.plot(self.radii, self.profile / self.noises, label="SNR-noise", color="blue")
        ax.plot(self.radii, self.profile / self.rms, label="SNR-std.", color="red")
        # plt.ylim(0,5)
        plt.legend()
        if self.show_plots:
            plt.show()


# main function to execute
def main(sys_argv):
    """
    Main function to execute the script.

    Parameters
    ----------
    sys_argv : list
        List of command-line arguments.
    """
    arg = sys_argv[1:]

    cube = Cube(arg[0], npca=15, nkmeans=2, show_plots=True)
    cube.give_best()  # give the best images
    cube.write_median_images(add_stars=True)  # write median images per cluster group to fits files

    print(f"Median data losses: {cube.kmeanfdata}")
    print(f"Median regularization loss: {cube.keamnfrgl}")
    print(f"Median total loss under regularization weight {cube.mu}: {cube.kmeanftot}")


# if used as a script
if __name__ == "__main__":
    print(sys.argv)
    main(sys.argv)
